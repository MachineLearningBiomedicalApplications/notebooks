{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Logistic Regression\n",
    "\n",
    "In this notebook we will review the main concepts of linear binary classification using an example of logistic regression. We will look at the univariate case - prediction of **heart failure** from a single feature, **Ejection Fraction**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "\n",
    "The code below\n",
    "* loads all the important libraries\n",
    "* implements function `accuracyCV` to calculate classification accuracy using cross-validation\n",
    "* implements function `plotData` to plot the dataset\n",
    "* creates feature matrix `X` that contains **Ejection Fraction** \n",
    "* creates label vector `y` that contains labels **Healthy=0** and **Heart Failure=1**\n",
    "\n",
    "Run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Calculate cross-validated accuracy\n",
    "def accuracyCV(model, X, y):\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring=\"accuracy\")\n",
    "    print('Mean cross-validated accuracy: ',round(scores.mean(),2))\n",
    "\n",
    "# Plot data\n",
    "def plotData(X,y,adjust_axis = True):\n",
    "    plt.figure(figsize=(7,3))\n",
    "    plt.plot(X[y==0], y[y==0], \"bo\", alpha=0.75, markeredgecolor='k', label = 'Healthy')\n",
    "    plt.plot(X[y==1], y[y==1], \"rd\", alpha=0.75, markeredgecolor='k', label = 'Heart Failure')\n",
    "    plt.plot(np.linspace(-2.5,2,100),np.zeros(100),'k:',alpha=0.5)\n",
    "\n",
    "    plt.xlabel('Feature: Scaled Ejection Fraction')\n",
    "    plt.ylabel('Label: Healthy=0, Heart Failure=1')\n",
    "    plt.legend()\n",
    "    \n",
    "    if adjust_axis:\n",
    "        plt.axis([-2.5,2,-0.1,1.1])\n",
    "\n",
    "#Load dataset\n",
    "df = pd.read_csv('datasets/heart_failure_data.csv')\n",
    "print('Dataframe columns: ', df.keys())\n",
    "scaler = StandardScaler()\n",
    "data = df.to_numpy()\n",
    "X = scaler.fit_transform(data[:,0].reshape(-1,1)) # Ejection Fraction\n",
    "print('Feature matrix X dimensions: ', X.shape)\n",
    "y = data[:,2] # Heart Failure\n",
    "print('Target vector y dimensions: ', y.shape)\n",
    "plotData(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Logistic regression model\n",
    "\n",
    "### Fit the model\n",
    "\n",
    "The code below\n",
    "* Selects the ```LogisticRegression``` model\n",
    "* Fits the model using all features and labels\n",
    "* Calculates the accuracy on whole set and using cross-validation\n",
    "\n",
    "Run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X,y)\n",
    "\n",
    "# Calculate the accuracy on the whole set\n",
    "print('Accuracy = ',round(model.score(X,y),2))\n",
    "\n",
    "# Calculate cross-validated accuracy \n",
    "accuracyCV(model,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Plot decision function\n",
    "\n",
    "The **decision function** for univariate classifier is defined as $h=w_0+w_1x$. The fitted classifiers in scikit-learn return the values of the decision function using `model.decision_function`.\n",
    "\n",
    "We will now plot the decision function of the fitted Logistic Regression model. Fist we will generate the feature space `x` for scaled EF, which covers interval [-2.5,2] as visible from the plot above.\n",
    "\n",
    "Your task is to \n",
    "* predict the decision function values `df` on the feature space `x`\n",
    "* plot the decision function\n",
    "\n",
    "The code for plotting the data is already there for you. Notices the output values of the decision function and the change of the scale in y-coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature space\n",
    "x = np.linspace(-2.5,2,100).reshape(-1,1)\n",
    "# Predict decision function\n",
    "df = None\n",
    "# Plot data\n",
    "plotData(X,y,adjust_axis=False)\n",
    "# Plot decision function\n",
    "plt.plot(None,None,'k', label = 'Decision function')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Plot decision boundary\n",
    "\n",
    "The **decision boundary**  of a linear classifier is defined by the setting the decision function to zero. In univariate case it is $w_0+w_1x=0$.\n",
    "\n",
    "Your task us to\n",
    "* Find the intercept $w_0$ and slope $w_1$\n",
    "* Calculate the decision boundary as $x=\\frac{-w_0}{w_1}$. \n",
    "\n",
    "*Hint:* Use `model.intercept_` and `model.coef_`. Remember that they are numpy arrays, so you need to select the first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intercept is a 1D array\n",
    "print('Intercept: ', np.around(model.intercept_,2))\n",
    "# coeficients are a 2D array\n",
    "print('Coefficients: ', np.around(model.coef_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract weights\n",
    "w0 = None\n",
    "w1 = None\n",
    "print('w0 = ', round(w0,2))\n",
    "print('w1 = ', round(w1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate decision boundary - note it is a scalar\n",
    "decision_boundary = None\n",
    "print('Decision boundary is ', round(decision_boundary,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "plotData(X,y,adjust_axis=False)\n",
    "\n",
    "# plot the decision boundary\n",
    "plt.plot([decision_boundary,decision_boundary],[-0.1,1.1], 'k', label = 'Decision boundary')\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Plot probabilitic predictions\n",
    "\n",
    "In binary logistic regression the confidence in predicted labels can be evaluated as $p(y=1|x)=\\sigma(h(x))$ and $p(y=0|x)=1-\\sigma(h(x))$. The probabilistic predictions are evaluated using function `model.predict_proba`. \n",
    "\n",
    "Your task is to calculate probabilistic predictions `proba` for the whole feature space and plot them. Check the dimensions of `proba`, you will see that the function returns probabilities for both classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate probabilistic predictions\n",
    "proba = None\n",
    "# check the dimension\n",
    "print('Dimensions of proba: ', proba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "plotData(X,y)\n",
    "\n",
    "# plot probabilistic predictions\n",
    "plt.plot(x,proba[:,0],'b:', label = 'Healthy Probability')\n",
    "plt.plot(x,proba[:,1],'r-', label = 'Heart Failure Probability')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Diagnosis\n",
    "\n",
    "A patient with suspicion of heart failure has an MRI scan. The ejection fraction is 40%. Decide whether the patient is likely to have a heart failure and calculate confidence in this decision.\n",
    "\n",
    "**Answer:** None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EF=40%\n",
    "x_new=40\n",
    "\n",
    "# convert the feature to a 2D numpy array\n",
    "# scale it using already fitted scaler\n",
    "x_new = scaler.transform(np.array(x_new).reshape(-1,1))\n",
    "print('Scaled EF: ', np.around(x_new,2))\n",
    "\n",
    "# predict the label\n",
    "y_new = None\n",
    "print('Predicted label: ', y_new)\n",
    "\n",
    "# predict confidence\n",
    "proba_new = None\n",
    "print('Predicted confidence: ', round(proba_new[0,y_new[0].astype(int)],2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
